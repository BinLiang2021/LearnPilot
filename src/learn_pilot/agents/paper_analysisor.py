"""
Paper Analysisor Agent
è®ºæ–‡åˆ†æAgentï¼Œä½¿ç”¨LLMè¿›è¡Œæ™ºèƒ½åˆ†æ
"""

import logging
import asyncio
from typing import List, Dict, Any, Optional
from pydantic import BaseModel, Field
import json

from src.learn_pilot.core.agents.structured_output_agent import StructuredOutputAgent
from src.learn_pilot.core.config.config import OPENAI_API_KEY, LANGUAGE
from src.learn_pilot.models.paper_models import Paper
from src.learn_pilot.literature_utils.markdown_parser import parse_papers_from_directory

logger = logging.getLogger(__name__)

class SectionSummary(BaseModel):
    sub_title: str
    summary: str

class PaperAnalysisOutput(BaseModel):
    """è®ºæ–‡åˆ†æè¾“å‡ºç»“æ„"""
    title: str
    authors: List[str]
    venue: str = Field(default="Unknown", description="å‘è¡¨ä¼šè®®æˆ–æœŸåˆŠ")
    year: str = Field(default="Unknown", description="å‘è¡¨å¹´ä»½")
    research_problem: str
    main_method: str
    key_contributions: List[str]
    core_concepts: List[str]
    difficulty_level: str = Field(description="éš¾åº¦çº§åˆ«: beginner, intermediate, advanced")
    reading_time_estimate: int = Field(description="é˜…è¯»æ—¶é—´ä¼°ç®—(åˆ†é’Ÿ)")
    section_summary: List[SectionSummary] = Field(description="ç« èŠ‚æ‘˜è¦å­—å…¸")
    technical_complexity: str = Field(description="æŠ€æœ¯å¤æ‚åº¦: low, medium, high")
    prerequisites: List[str]

class PaperAnalysisor:
    """è®ºæ–‡åˆ†æå™¨Agent - LLMé©±åŠ¨ç‰ˆæœ¬"""
    
    def __init__(self, config: Dict[str, Any] = None):
        self.config = config or {}
        self.logger = logger
        self.model = self.config.get("model", "gpt-4o-2024-11-20")
        
    async def analyze_papers(self, input_dir: str) -> Dict[str, Any]:
        """åˆ†æè®ºæ–‡ç›®å½•ä¸­çš„æ‰€æœ‰è®ºæ–‡"""
        try:
            self.logger.info(f"ğŸ” å¼€å§‹åˆ†æè®ºæ–‡ç›®å½•: {input_dir}")
            
            # è§£æè®ºæ–‡æ–‡ä»¶
            papers = parse_papers_from_directory(input_dir)
            
            if not papers:
                self.logger.warning("æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„è®ºæ–‡æ–‡ä»¶")
                return {"papers": [], "analysis_results": {}}
            
            # ä½¿ç”¨LLMåˆ†ææ¯ç¯‡è®ºæ–‡
            analysis_results = {}
            for i, paper in enumerate(papers):
                paper_id = f"paper_{i+1}"
                self.logger.info(f"ğŸ“ åˆ†æè®ºæ–‡ {paper_id}: {paper.title}")
                
                analysis = await self._analyze_single_paper_with_llm(paper)
                analysis_results[paper_id] = analysis
            
            # ç”Ÿæˆæ•´ä½“åˆ†ææŠ¥å‘Š
            overall_analysis = await self._generate_overall_analysis(analysis_results)
            
            result = {
                "papers": papers,
                "analysis_results": analysis_results,
                "overall_analysis": overall_analysis,
                "paper_ids": list(analysis_results.keys())
            }
            
            self.logger.info(f"âœ… è®ºæ–‡åˆ†æå®Œæˆ: {len(papers)} ç¯‡è®ºæ–‡")
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ è®ºæ–‡åˆ†æå¤±è´¥: {e}")
            raise
    
    async def _analyze_single_paper_with_llm(self, paper: Paper) -> Dict[str, Any]:
        """ä½¿ç”¨LLMåˆ†æå•ç¯‡è®ºæ–‡"""
        
        # æ„å»ºè®ºæ–‡å†…å®¹
        paper_content = f"""
æ ‡é¢˜: {paper.title}

ä½œè€…: {', '.join(author.name for author in paper.authors)}

æ‘˜è¦:
{paper.abstract}

ç« èŠ‚å†…å®¹:
"""
        for section in paper.sections:
            paper_content += f"\n## {section.title}\n{section.content}\n"
        
        # æ„å»ºåˆ†æprompt
        instructions = f"""
ä½ æ˜¯ä¸€ä½èµ„æ·±çš„å­¦æœ¯è®ºæ–‡åˆ†æä¸“å®¶ã€‚è¯·ä»”ç»†åˆ†æä»¥ä¸‹è®ºæ–‡ï¼Œæå–å…³é”®ä¿¡æ¯å¹¶è¿›è¡Œæ·±åº¦åˆ†æã€‚

è¯·åˆ†æè®ºæ–‡çš„ï¼š
1. åŸºæœ¬ä¿¡æ¯ï¼ˆæ ‡é¢˜ã€ä½œè€…ã€å‘è¡¨ä¿¡æ¯ç­‰ï¼‰
2. ç ”ç©¶é—®é¢˜å’Œä¸»è¦æ–¹æ³•
3. æ ¸å¿ƒè´¡çŒ®å’Œå…³é”®æ¦‚å¿µ
4. æŠ€æœ¯éš¾åº¦å’Œå­¦ä¹ è¦æ±‚
5. å„ç« èŠ‚å†…å®¹æ‘˜è¦

æ³¨æ„ï¼š
- æ‰€æœ‰åˆ†æå†…å®¹è¯·ç”¨{LANGUAGE}å›ç­”
- éš¾åº¦çº§åˆ«åˆ†ä¸º beginner/intermediate/advanced
- æŠ€æœ¯å¤æ‚åº¦åˆ†ä¸º low/medium/high  
- é˜…è¯»æ—¶é—´ä¼°ç®—åŸºäºç ”ç©¶ç”Ÿæ°´å¹³ï¼ˆåˆ†é’Ÿï¼‰
- å‰ç½®çŸ¥è¯†åº”è¯¥å…·ä½“ä¸”å®ç”¨
"""

        # åˆ›å»ºLLMåˆ†æå™¨
        analyzer = StructuredOutputAgent(
            model=self.model,
            api_key=OPENAI_API_KEY,
            instructions=instructions,
            output_type=PaperAnalysisOutput
        )
        
        input_messages = [
            {
                "role": "user", 
                "content": f"è¯·åˆ†æä»¥ä¸‹è®ºæ–‡ï¼š\n\n{paper_content}"
            }
        ]
        
        # æ‰§è¡Œåˆ†æ
        result = await analyzer.run(input_messages)
        return result
    
    async def _generate_overall_analysis(self, analysis_results: Dict[str, Dict[str, Any]]) -> Dict[str, Any]:
        """ç”Ÿæˆæ•´ä½“åˆ†æ"""
        
        # æå–æ‰€æœ‰åˆ†æç»“æœ
        all_analyses = []
        for paper_id, result in analysis_results.items():
            analysis = result['output']
            all_analyses.append({
                'paper_id': paper_id,
                'title': analysis['title'],
                'difficulty_level': analysis['difficulty_level'],
                'core_concepts': analysis['core_concepts'],
                'prerequisites': analysis['prerequisites'],
                'reading_time': analysis['reading_time_estimate']
            })
        
        # ä½¿ç”¨LLMç”Ÿæˆæ•´ä½“åˆ†æ
        overall_prompt = f"""
åŸºäºä»¥ä¸‹è®ºæ–‡é›†çš„åˆ†æç»“æœï¼Œè¯·ç”Ÿæˆä¸€ä¸ªæ•´ä½“çš„å­¦ä¹ å»ºè®®å’Œåˆ†ææ€»ç»“ï¼š

{json.dumps(all_analyses, ensure_ascii=False, indent=2)}

è¯·åˆ†æï¼š
1. è®ºæ–‡é›†çš„æ•´ä½“éš¾åº¦åˆ†å¸ƒ
2. æ ¸å¿ƒæ¦‚å¿µçš„åˆ†å¸ƒå’Œå…³è”
3. æ¨èçš„å­¦ä¹ é¡ºåº
4. æ€»ä½“å­¦ä¹ æ—¶é—´ä¼°ç®—
5. å­¦ä¹ å»ºè®®å’Œæ³¨æ„äº‹é¡¹

ç”¨{LANGUAGE}å›ç­”ï¼Œæä¾›å…·ä½“å¯æ“ä½œçš„å»ºè®®ã€‚
"""

        class DifficultyDistribution(BaseModel):
            level: str
            count: int
            
        class ConceptCluster(BaseModel):
            concept: str
            related_concepts: List[str]

        # ä½¿ç”¨ç®€å•çš„LLMè°ƒç”¨ç”Ÿæˆæ€»ç»“
        class OverallAnalysisOutput(BaseModel):
            difficulty_distribution: List[DifficultyDistribution] = Field(description="éš¾åº¦åˆ†å¸ƒç»Ÿè®¡")
            common_concepts: List[str] = Field(description="å…±åŒæ¦‚å¿µåˆ—è¡¨")
            recommended_order: List[str] = Field(description="æ¨èè®ºæ–‡å­¦ä¹ é¡ºåº")
            total_estimated_time: int = Field(description="æ€»å­¦ä¹ æ—¶é—´(åˆ†é’Ÿ)")
            learning_suggestions: List[str] = Field(description="å­¦ä¹ å»ºè®®åˆ—è¡¨")
            concept_clusters: List[ConceptCluster] = Field(description="æ¦‚å¿µèšç±»")

        analyzer = StructuredOutputAgent(
            model=self.model,
            api_key=OPENAI_API_KEY,
            instructions="ä½ æ˜¯å­¦ä¹ è§„åˆ’ä¸“å®¶ï¼Œè¯·åŸºäºè®ºæ–‡åˆ†æç»“æœç”Ÿæˆæ•´ä½“å­¦ä¹ å»ºè®®ã€‚",
            output_type=OverallAnalysisOutput
        )
        
        result = await analyzer.run([{"role": "user", "content": overall_prompt}])
        return result
    
    def save_analysis_results(self, results: Dict[str, Any], output_dir: str):
        """ä¿å­˜åˆ†æç»“æœ"""
        import os
        os.makedirs(output_dir, exist_ok=True)
        
        # ä¿å­˜è¯¦ç»†åˆ†æç»“æœ
        analysis_file = os.path.join(output_dir, "paper_analysis.json")
        
        # å‡†å¤‡å¯åºåˆ—åŒ–çš„æ•°æ®
        serializable_results = {
            "analysis_results": {},
            "overall_analysis": results.get("overall_analysis", {}),
            "paper_ids": results.get("paper_ids", [])
        }
        
        # è½¬æ¢åˆ†æç»“æœ
        for paper_id, result in results.get("analysis_results", {}).items():
            serializable_results["analysis_results"][paper_id] = {
                "output": result["output"],
                "usage": result["usage"]
            }
        
        with open(analysis_file, 'w', encoding='utf-8') as f:
            json.dump(serializable_results, f, indent=2, ensure_ascii=False)
        
        # ç”Ÿæˆç®€è¦æŠ¥å‘Š
        report = self._generate_simple_report(results)
        report_file = os.path.join(output_dir, "analysis_report.md")
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
        
        self.logger.info(f"ğŸ“Š åˆ†æç»“æœå·²ä¿å­˜åˆ°: {output_dir}")
    
    def _generate_simple_report(self, results: Dict[str, Any]) -> str:
        """ç”Ÿæˆç®€è¦æŠ¥å‘Š"""
        lines = ["# ğŸ“š è®ºæ–‡åˆ†ææŠ¥å‘Š", ""]
        
        analysis_results = results.get("analysis_results", {})
        overall = results.get("overall_analysis", {}).get("output", {})
        
        # åŸºæœ¬ç»Ÿè®¡
        lines.append("## ğŸ“Š åŸºæœ¬ç»Ÿè®¡")
        lines.append(f"- è®ºæ–‡æ€»æ•°: {len(analysis_results)}")
        
        if overall.get("difficulty_distribution"):
            lines.append("- éš¾åº¦åˆ†å¸ƒ:")
            for data in overall["difficulty_distribution"]:
                level = data['level']
                count = data['count']
                lines.append(f"  - {level}: {count} ç¯‡")
        
        if overall.get("total_estimated_time"):
            lines.append(f"- æ€»å­¦ä¹ æ—¶é—´: {overall['total_estimated_time']} åˆ†é’Ÿ")
        
        lines.append("")
        
        # æ¨èå­¦ä¹ é¡ºåº
        if overall.get("recommended_order"):
            lines.append("## ğŸ“‹ æ¨èå­¦ä¹ é¡ºåº")
            for i, paper_id in enumerate(overall["recommended_order"], 1):
                if paper_id in analysis_results:
                    title = analysis_results[paper_id]["output"]["title"]
                    difficulty = analysis_results[paper_id]["output"]["difficulty_level"]
                    time = analysis_results[paper_id]["output"]["reading_time_estimate"]
                    lines.append(f"{i}. **{title}** ({difficulty}, {time}åˆ†é’Ÿ)")
            lines.append("")
        
        # æ ¸å¿ƒæ¦‚å¿µ
        if overall.get("common_concepts"):
            lines.append("## ğŸ¯ æ ¸å¿ƒæ¦‚å¿µ")
            for concept in overall["common_concepts"][:10]:
                lines.append(f"- {concept}")
            lines.append("")
        
        # å­¦ä¹ å»ºè®®
        if overall.get("learning_suggestions"):
            lines.append("## ğŸ’¡ å­¦ä¹ å»ºè®®")
            for suggestion in overall["learning_suggestions"]:
                lines.append(f"- {suggestion}")
            lines.append("")
        
        return "\n".join(lines)

# ä¾¿æ·å‡½æ•°
async def analyze_papers_directory(input_dir: str, output_dir: str = None) -> Dict[str, Any]:
    """ä¾¿æ·å‡½æ•°ï¼šåˆ†æè®ºæ–‡ç›®å½•"""
    analyzer = PaperAnalysisor()
    results = await analyzer.analyze_papers(input_dir)
    
    if output_dir:
        analyzer.save_analysis_results(results, output_dir)
    
    return results

if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    async def test():
        analyzer = PaperAnalysisor()
        print("âœ… PaperAnalysisor åˆå§‹åŒ–å®Œæˆ")
    
    asyncio.run(test()) 