"""
@file_name: db_viewer.py
@author: bin.liang
@date: 2025-06-28
@description: è®ºæ–‡æ•°æ®åº“æŸ¥çœ‹å™¨ - æä¾›æ•°æ®æŸ¥è¯¢ã€ç»Ÿè®¡ã€å¯¼å‡ºç­‰åŠŸèƒ½
"""

import asyncio
import json
import sqlite3
from typing import List, Dict, Any, Optional
from datetime import datetime
from pathlib import Path
from tabulate import tabulate

from src.learn_pilot.tools.file_system.paper_repository import PaperRepository
from src.learn_pilot.core.logging.logger import logger


class PaperDBViewer:
    """è®ºæ–‡æ•°æ®åº“æŸ¥çœ‹å™¨"""
    
    def __init__(self, db_path: Optional[str] = None):
        self.repository = PaperRepository(db_path)
        
    async def show_stats(self) -> Dict[str, Any]:
        """æ˜¾ç¤ºæ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯"""
        stats = await self.repository.get_stats()
        
        print("=" * 60)
        print("ğŸ“Š æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯")
        print("=" * 60)
        print(f"ğŸ“š è®ºæ–‡æ€»æ•°: {stats['total_papers']}")
        print(f"âœ… å·²å¤„ç†è®ºæ–‡: {stats['processed_papers']}")
        print(f"ğŸ” ç ”ç©¶é¢†åŸŸæ•°: {stats['unique_fields']}")
        print(f"ğŸ“… æœ€è¿‘æ·»åŠ : {stats['latest_added'] or 'æ— '}")
        
        if stats['total_papers'] > 0:
            success_rate = (stats['processed_papers'] / stats['total_papers']) * 100
            print(f"ğŸ“ˆ å¤„ç†æˆåŠŸç‡: {success_rate:.1f}%")
        
        print("=" * 60)
        return stats
    
    async def list_papers(self, limit: int = 20, offset: int = 0) -> List[Dict]:
        """åˆ—å‡ºè®ºæ–‡åˆ—è¡¨"""
        papers = await asyncio.get_event_loop().run_in_executor(
            None, self._get_papers_with_pagination, limit, offset
        )
        
        if not papers:
            print("ğŸ“­ æš‚æ— è®ºæ–‡æ•°æ®")
            return []
        
        # æ ¼å¼åŒ–æ˜¾ç¤º
        table_data = []
        for paper in papers:
            # è§£æç ”ç©¶é¢†åŸŸ
            try:
                fields = json.loads(paper['research_fields']) if paper['research_fields'] else []
                fields_str = ', '.join(fields[:2])  # åªæ˜¾ç¤ºå‰ä¸¤ä¸ªé¢†åŸŸ
                if len(fields) > 2:
                    fields_str += f" (+{len(fields)-2})"
            except:
                fields_str = paper['research_fields'] or 'N/A'
            
            # å¤„ç†å¯èƒ½æ˜¯å­—ç¬¦ä¸²çš„å­—æ®µï¼Œä¸è¦å½“ä½œåˆ—è¡¨å¤„ç†
            key_contribution = paper.get('key_contribution', '') or ''
            key_concepts_and_techniques = paper.get('key_concepts_and_techniques', '') or ''
            
            # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥ä½¿ç”¨ï¼›å¦‚æœæ˜¯åˆ—è¡¨ï¼Œåˆ™è¿æ¥
            if isinstance(key_contribution, list):
                key_contribution = ', '.join(key_contribution)
            if isinstance(key_concepts_and_techniques, list):
                key_concepts_and_techniques = ', '.join(key_concepts_and_techniques)
            
            table_data.append([
                paper['id'],
                paper['title'][:50] + ('...' if len(paper['title']) > 50 else ''),
                fields_str,
                paper.get('research_problem', '')[:50] + ('...' if len(paper.get('research_problem', '')) > 50 else ''),
                key_contribution[:50] + ('...' if len(key_contribution) > 50 else ''),
                key_concepts_and_techniques[:50] + ('...' if len(key_concepts_and_techniques) > 50 else ''),
                'âœ…' if paper['is_processed'] else 'â³',
                paper['add_date'] or 'N/A'
            ])
        
        headers = ['ID', 'Title', 'Fields', 'Problem', 'Contribution', 'Techniques', 'Status', 'Date']
        print(f"\nğŸ“‹ è®ºæ–‡åˆ—è¡¨ (æ˜¾ç¤º {offset+1}-{offset+len(papers)} æ¡)")
        print(tabulate(table_data, headers=headers, tablefmt='grid', maxcolwidths=[4, 40, 20, 30, 30, 30, 8, 12]))
        
        return papers
    
    async def search_papers(self, keyword: str) -> List[Dict]:
        """æœç´¢è®ºæ–‡"""
        papers = await asyncio.get_event_loop().run_in_executor(
            None, self._search_papers_sync, keyword
        )
        
        if not papers:
            print(f"ğŸ” æœªæ‰¾åˆ°åŒ…å« '{keyword}' çš„è®ºæ–‡")
            return []
        
        print(f"\nğŸ” æœç´¢ç»“æœ: æ‰¾åˆ° {len(papers)} ç¯‡è®ºæ–‡")
        await self._display_paper_list(papers)
        return papers
    
    async def show_papers_by_field(self, field: str) -> List[Dict]:
        """æŒ‰ç ”ç©¶é¢†åŸŸæ˜¾ç¤ºè®ºæ–‡"""
        papers = await self.repository.get_papers_by_field(field)
        
        if not papers:
            print(f"ğŸ“­ æœªæ‰¾åˆ° '{field}' é¢†åŸŸçš„è®ºæ–‡")
            return []
        
        print(f"\nğŸ·ï¸ '{field}' é¢†åŸŸè®ºæ–‡ ({len(papers)} ç¯‡)")
        await self._display_paper_list(papers)
        return papers
    
    async def show_paper_detail(self, paper_id: int):
        """æ˜¾ç¤ºè®ºæ–‡è¯¦æƒ…"""
        paper = await asyncio.get_event_loop().run_in_executor(
            None, self._get_paper_by_id, paper_id
        )
        
        if not paper:
            print(f"âŒ æœªæ‰¾åˆ°IDä¸º {paper_id} çš„è®ºæ–‡")
            return
        
        print("\n" + "=" * 80)
        print("ğŸ“„ è®ºæ–‡è¯¦æƒ…")
        print("=" * 80)
        print(f"ğŸ†” ID: {paper['id']}")
        print(f"ğŸ“ æ ‡é¢˜: {paper['title']}")
        print(f"ğŸ“… æ·»åŠ æ—¥æœŸ: {paper['add_date']}")
        print(f"ğŸ·ï¸ å­˜å‚¨ç±»å‹: {paper.get('store_type', 'unknown')}")
        print(f"âœ… å¤„ç†çŠ¶æ€: {'å·²å¤„ç†' if paper['is_processed'] else 'æœªå¤„ç†'}")
        
        # ç ”ç©¶é¢†åŸŸ
        try:
            fields = json.loads(paper['research_fields']) if paper['research_fields'] else []
            print(f"ğŸ”¬ ç ”ç©¶é¢†åŸŸ: {', '.join(fields) if fields else 'N/A'}")
        except:
            print(f"ğŸ”¬ ç ”ç©¶é¢†åŸŸ: {paper['research_fields'] or 'N/A'}")
        
        print(f"ğŸ”— URL: {paper.get('url', 'N/A')}")
        print(f"ğŸ“ PDFè·¯å¾„: {paper.get('pdf_path') or 'æœªä¸‹è½½'}")
        print(f"ğŸ“„ Markdownè·¯å¾„: {paper.get('markdown_path') or 'æ— '}")
        
        # ç ”ç©¶é—®é¢˜
        if paper.get('research_problem'):
            print(f"\nğŸ¯ ç ”ç©¶é—®é¢˜:")
            print(f"   {paper['research_problem']}")
        
        # å…³é”®è´¡çŒ®
        if paper.get('key_contribution'):
            print(f"\nğŸ’¡ å…³é”®è´¡çŒ®:")
            print(f"   {paper['key_contribution']}")
        
        # å…³é”®æ¦‚å¿µå’ŒæŠ€æœ¯
        if paper.get('key_concepts_and_techniques'):
            print(f"\nğŸ”§ å…³é”®æ¦‚å¿µå’ŒæŠ€æœ¯:")
            print(f"   {paper['key_concepts_and_techniques']}")
        
        # æ‘˜è¦
        if paper.get('summary'):
            print(f"\nğŸ“‹ æ‘˜è¦:")
            # æ ¼å¼åŒ–æ‘˜è¦æ˜¾ç¤º
            summary_lines = [paper['summary'][i:i+80] for i in range(0, len(paper['summary']), 80)]
            for line in summary_lines:
                print(f"   {line}")
        
        print("=" * 80)
    
    async def list_fields(self) -> List[str]:
        """åˆ—å‡ºæ‰€æœ‰ç ”ç©¶é¢†åŸŸ"""
        fields = await asyncio.get_event_loop().run_in_executor(
            None, self._get_all_fields
        )
        
        print("\nğŸ·ï¸ æ‰€æœ‰ç ”ç©¶é¢†åŸŸ:")
        for i, (field, count) in enumerate(fields, 1):
            print(f"   {i:2d}. {field:<20} ({count} ç¯‡)")
        
        return [field for field, _ in fields]
    
    async def export_data(self, output_file: str = None) -> str:
        """å¯¼å‡ºæ•°æ®"""
        if not output_file:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_file = f"papers_export_{timestamp}.json"
        
        backup_path = await self.repository.backup_to_json(output_file)
        print(f"ğŸ“ æ•°æ®å·²å¯¼å‡ºåˆ°: {backup_path}")
        return backup_path
    
    async def cleanup_database(self):
        """æ¸…ç†æ•°æ®åº“ï¼ˆåˆ é™¤æœªå¤„ç†çš„è®ºæ–‡ï¼‰"""
        count = await asyncio.get_event_loop().run_in_executor(
            None, self._cleanup_unprocessed
        )
        print(f"ğŸ§¹ å·²æ¸…ç† {count} æ¡æœªå¤„ç†çš„è®ºæ–‡è®°å½•")
    
    # åŒæ­¥è¾…åŠ©æ–¹æ³•
    def _get_papers_with_pagination(self, limit: int, offset: int) -> List[Dict]:
        """åˆ†é¡µè·å–è®ºæ–‡"""
        with sqlite3.connect(self.repository.db_path) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.execute("""
                SELECT * FROM papers 
                ORDER BY created_at DESC 
                LIMIT ? OFFSET ?
            """, (limit, offset))
            return [dict(row) for row in cursor.fetchall()]
    
    def _search_papers_sync(self, keyword: str) -> List[Dict]:
        """åŒæ­¥æœç´¢è®ºæ–‡"""
        with sqlite3.connect(self.repository.db_path) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.execute("""
                SELECT * FROM papers 
                WHERE title LIKE ? OR summary LIKE ?
                ORDER BY created_at DESC
            """, (f'%{keyword}%', f'%{keyword}%'))
            return [dict(row) for row in cursor.fetchall()]
    
    def _get_paper_by_id(self, paper_id: int) -> Optional[Dict]:
        """æ ¹æ®IDè·å–è®ºæ–‡"""
        with sqlite3.connect(self.repository.db_path) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.execute("SELECT * FROM papers WHERE id = ?", (paper_id,))
            row = cursor.fetchone()
            return dict(row) if row else None
    
    def _get_all_fields(self) -> List[tuple]:
        """è·å–æ‰€æœ‰ç ”ç©¶é¢†åŸŸåŠè®ºæ–‡æ•°é‡"""
        with sqlite3.connect(self.repository.db_path) as conn:
            cursor = conn.execute("""
                SELECT research_fields, COUNT(*) as count
                FROM papers 
                WHERE research_fields IS NOT NULL 
                GROUP BY research_fields
                ORDER BY count DESC
            """)
            
            # è§£æJSONå­—æ®µå¹¶ç»Ÿè®¡
            field_counts = {}
            for row in cursor.fetchall():
                try:
                    fields = json.loads(row[0]) if row[0] else []
                    for field in fields:
                        field_counts[field] = field_counts.get(field, 0) + row[1]
                except:
                    continue
            
            return sorted(field_counts.items(), key=lambda x: x[1], reverse=True)
    
    def _cleanup_unprocessed(self) -> int:
        """æ¸…ç†æœªå¤„ç†çš„è®ºæ–‡"""
        with sqlite3.connect(self.repository.db_path) as conn:
            cursor = conn.execute("DELETE FROM papers WHERE is_processed = 0")
            return cursor.rowcount
    
    async def _display_paper_list(self, papers: List[Dict], max_display: int = 10):
        """æ˜¾ç¤ºè®ºæ–‡åˆ—è¡¨"""
        display_papers = papers[:max_display]
        
        table_data = []
        for paper in display_papers:
            try:
                fields = json.loads(paper['research_fields']) if paper['research_fields'] else []
                fields_str = ', '.join(fields[:2])
                if len(fields) > 2:
                    fields_str += f" (+{len(fields)-2})"
            except:
                fields_str = 'N/A'
            
            table_data.append([
                paper['id'],
                paper['title'][:50] + ('...' if len(paper['title']) > 50 else ''),
                paper['research_problem'][:50] + ('...' if len(paper['research_problem']) > 50 else ''),
                paper['key_contribution'][:50] + ('...' if len(paper['key_contribution']) > 50 else ''),
                paper['key_concepts_and_techniques'][:50] + ('...' if len(paper['key_concepts_and_techniques']) > 50 else ''),
                fields_str[:25] + ('...' if len(fields_str) > 25 else ''),
                'âœ…' if paper['is_processed'] else 'â³',
                paper['add_date'] or 'N/A'
            ])
        
        headers = ['ID', 'Title', 'Fields', 'Problem', 'Contribution', 'Techniques', 'Status', 'Date']
        print(tabulate(table_data, headers=headers, tablefmt='grid', maxcolwidths=[4, 50, 25, 25, 25, 25, 8, 12]))
        
        if len(papers) > max_display:
            print(f"\n... è¿˜æœ‰ {len(papers) - max_display} ç¯‡è®ºæ–‡æœªæ˜¾ç¤º") 