"""
@file_name: paper_repository.py
@author: bin.liang
@date: 2025-06-28
@description: è®ºæ–‡æ•°æ®ä»“åº“ - æä¾›å®‰å…¨çš„æ•°æ®å­˜å‚¨å’ŒæŸ¥è¯¢åŠŸèƒ½
"""

import json
import sqlite3
import asyncio
from pathlib import Path
import traceback
from typing import List, Dict, Any, Optional
from datetime import datetime
from contextlib import asynccontextmanager

from src.learn_pilot.core.logging.logger import logger
from src.learn_pilot.core.config.config import DATA_DIR


class PaperRepository:
    """è®ºæ–‡æ•°æ®ä»“åº“ - ä½¿ç”¨SQLiteæä¾›å¯é çš„æ•°æ®å­˜å‚¨"""
    
    def __init__(self, db_path: Optional[str] = None):
        self.db_path = db_path or f"{DATA_DIR}/papers.db"
        self._ensure_db_exists()
        
    def _ensure_db_exists(self):
        """ç¡®ä¿æ•°æ®åº“å’Œè¡¨å­˜åœ¨"""
        Path(self.db_path).parent.mkdir(parents=True, exist_ok=True)
        
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("""
                CREATE TABLE IF NOT EXISTS papers (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    title TEXT NOT NULL,
                    research_problem TEXT,
                    key_contribution TEXT,
                    key_concepts_and_techniques TEXT,
                    summary TEXT,
                    url TEXT UNIQUE,
                    pdf_path TEXT,
                    markdown_path TEXT DEFAULT "",
                    research_fields TEXT,  -- JSON array
                    add_date TEXT,
                    store_type TEXT,
                    is_processed BOOLEAN DEFAULT 0,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            # ä¸ºå·²å­˜åœ¨çš„è¡¨æ·»åŠ æ–°å­—æ®µï¼ˆå¦‚æœä¸å­˜åœ¨çš„è¯ï¼‰
            try:
                conn.execute("ALTER TABLE papers ADD COLUMN markdown_path TEXT DEFAULT ''")
            except sqlite3.OperationalError:
                # å­—æ®µå·²å­˜åœ¨ï¼Œå¿½ç•¥é”™è¯¯
                pass
            
            # åˆ›å»ºç´¢å¼•æé«˜æŸ¥è¯¢æ€§èƒ½
            conn.execute("CREATE INDEX IF NOT EXISTS idx_url ON papers(url)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_fields ON papers(research_fields)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_date ON papers(add_date)")
            
    def _convert_to_string(self, value: Any) -> str:
        """å°†å€¼è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œç‰¹æ®Šå¤„ç†listç±»å‹"""
        if isinstance(value, list):
            return '\n'.join(str(item) for item in value) if value else ''
        elif value is None:
            return ''
        else:
            return str(value)
    
    async def save_paper(self, paper_data: Dict[str, Any]) -> bool:
        """
        ä¿å­˜è®ºæ–‡æ•°æ®ï¼Œæ”¯æŒäº‹åŠ¡å’Œé‡å¤æ£€æŸ¥
        
        Args:
            paper_data: è®ºæ–‡æ•°æ®å­—å…¸
            
        Returns:
            æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        try:
            # è½¬æ¢æ•°æ®æ ¼å¼ï¼Œç¡®ä¿æ‰€æœ‰å­—æ®µéƒ½æ˜¯æ­£ç¡®çš„ç±»å‹
            processed_data = {
                'title': self._convert_to_string(paper_data.get('title', '')),
                'research_problem': self._convert_to_string(paper_data.get('research_problem', '')),
                'key_contribution': self._convert_to_string(paper_data.get('key_contribution', '')),
                'key_concepts_and_techniques': self._convert_to_string(paper_data.get('key_concepts_and_techniques', '')),
                'summary': self._convert_to_string(paper_data.get('summary', '')),
                'url': self._convert_to_string(paper_data.get('url', '')),
                'pdf_path': paper_data.get('pdf_path'),
                'markdown_path': self._convert_to_string(paper_data.get('markdown_path', '')),
                'research_fields': json.dumps(paper_data.get('research_fields', [])),
                'add_date': paper_data.get('add_date', datetime.now().strftime("%Y-%m-%d")),
                'store_type': paper_data.get('store_type', 'unknown'),
                'is_processed': 1 if paper_data.get('pdf_path') else 0
            }
            
            # å¼‚æ­¥æ‰§è¡Œæ•°æ®åº“æ“ä½œ
            await asyncio.get_event_loop().run_in_executor(
                None, self._save_to_db, processed_data
            )
            
            logger.info(f"ğŸ’¾ è®ºæ–‡å·²ä¿å­˜: {processed_data['title'][:50]}...")
            return True
            
        except Exception as e:
            error_message = traceback.format_exc()
            logger.error(f"âŒ é”™è¯¯ä¿¡æ¯: {error_message}")
            return False
            
    def _save_to_db(self, data: Dict[str, Any]):
        """åŒæ­¥ä¿å­˜åˆ°æ•°æ®åº“"""
        with sqlite3.connect(self.db_path) as conn:
            # ä½¿ç”¨ INSERT OR REPLACE é¿å…é‡å¤
            conn.execute("""
                INSERT OR REPLACE INTO papers (
                    title, research_problem, key_contribution, key_concepts_and_techniques, 
                    summary, url, pdf_path, markdown_path, research_fields,
                    add_date, store_type, is_processed
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                data['title'], data['research_problem'], data['key_contribution'], 
                data['key_concepts_and_techniques'], data['summary'], data['url'], 
                data['pdf_path'], data['markdown_path'], data['research_fields'],
                data['add_date'], 
                data['store_type'], data['is_processed']
            ))
            
    async def get_papers_by_field(self, field: str) -> List[Dict[str, Any]]:
        """æ ¹æ®ç ”ç©¶é¢†åŸŸæŸ¥è¯¢è®ºæ–‡"""
        return await asyncio.get_event_loop().run_in_executor(
            None, self._query_by_field, field
        )
        
    def _query_by_field(self, field: str) -> List[Dict[str, Any]]:
        """åŒæ­¥æŸ¥è¯¢æŒ‡å®šé¢†åŸŸçš„è®ºæ–‡"""
        with sqlite3.connect(self.db_path) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.execute(
                "SELECT * FROM papers WHERE research_fields LIKE ? ORDER BY created_at DESC",
                (f'%{field}%',)
            )
            return [dict(row) for row in cursor.fetchall()]
            
    async def get_stats(self) -> Dict[str, Any]:
        """è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯"""
        return await asyncio.get_event_loop().run_in_executor(
            None, self._get_stats
        )
        
    def _get_stats(self) -> Dict[str, Any]:
        """åŒæ­¥è·å–ç»Ÿè®¡ä¿¡æ¯"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute("""
                SELECT 
                    COUNT(*) as total,
                    SUM(is_processed) as processed,
                    COUNT(DISTINCT research_fields) as unique_fields,
                    MAX(created_at) as latest_added
                FROM papers
            """)
            row = cursor.fetchone()
            
            return {
                'total_papers': row[0],
                'processed_papers': row[1],
                'unique_fields': row[2],
                'latest_added': row[3]
            }
            
    async def backup_to_json(self, backup_path: Optional[str] = None) -> str:
        """å¤‡ä»½æ•°æ®åˆ°JSONæ–‡ä»¶"""
        backup_path = backup_path or f"{DATA_DIR}/backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        papers = await asyncio.get_event_loop().run_in_executor(
            None, self._get_all_papers
        )
        
        with open(backup_path, 'w', encoding='utf-8') as f:
            json.dump(papers, f, ensure_ascii=False, indent=2)
            
        logger.info(f"ğŸ“ æ•°æ®å·²å¤‡ä»½åˆ°: {backup_path}")
        return backup_path
        
    def _get_all_papers(self) -> List[Dict[str, Any]]:
        """è·å–æ‰€æœ‰è®ºæ–‡æ•°æ®"""
        with sqlite3.connect(self.db_path) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.execute("SELECT * FROM papers ORDER BY created_at DESC")
            return [dict(row) for row in cursor.fetchall()] 
        