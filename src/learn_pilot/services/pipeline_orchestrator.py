"""
Pipeline Orchestrator
æµæ°´çº¿ç¼–æ’å™¨ï¼Œåè°ƒå„ä¸ªAgentçš„æ‰§è¡Œ
"""

import logging
import asyncio
from typing import Dict, Any, Optional
import os

from src.learn_pilot.agents.paper_analysisor import PaperAnalysisor
from src.learn_pilot.agents.knowledge_extractor import KnowledgeExtractor

logger = logging.getLogger(__name__)

class PipelineOrchestrator:
    """AI-Paper-Tutor æµæ°´çº¿ç¼–æ’å™¨"""
    
    def __init__(self, config: Dict[str, Any] = None):
        self.config = config or {}
        self.logger = logger
        
        # åˆå§‹åŒ–Agent
        self.paper_analysisor = PaperAnalysisor(config)
        self.knowledge_extractor = KnowledgeExtractor(config)
        
    async def run_full_pipeline(self, input_dir: str, output_dir: str, 
                               user_preferences: Dict[str, Any] = None) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´çš„AI-Paper-Tutoræµæ°´çº¿"""
        try:
            self.logger.info("ğŸš€ å¯åŠ¨å®Œæ•´AI-Paper-Tutoræµæ°´çº¿")
            
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            os.makedirs(output_dir, exist_ok=True)
            
            results = {}
            
            # Step 1: è®ºæ–‡åˆ†æ
            self.logger.info("ğŸ“Š Step 1: è®ºæ–‡åˆ†æ")
            analysis_results = await self.paper_analysisor.analyze_papers(input_dir)
            results['analysis'] = analysis_results
            self.paper_analysisor.save_analysis_results(analysis_results, 
                                                       os.path.join(output_dir, "analysis"))
            
            # Step 2: æ¦‚å¿µæå–
            self.logger.info("ğŸ§  Step 2: æ¦‚å¿µæå–")
            papers = analysis_results.get('papers', [])
            if papers:
                extraction_results = await self.knowledge_extractor.extract_concepts_from_papers(papers)
                results['extraction'] = extraction_results
                self.knowledge_extractor.save_extraction_results(extraction_results, 
                                                                os.path.join(output_dir, "extraction"))
            
            # Step 3: ç”Ÿæˆæ•´ä½“æŠ¥å‘Š
            self.logger.info("ğŸ“ Step 3: ç”Ÿæˆæ•´ä½“æŠ¥å‘Š")
            overall_report = self._generate_pipeline_report(results, user_preferences)
            
            # ä¿å­˜æ•´ä½“æŠ¥å‘Š
            report_file = os.path.join(output_dir, "pipeline_report.md")
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write(overall_report)
            
            results['pipeline_report'] = overall_report
            results['output_dir'] = output_dir
            
            self.logger.info("âœ… AI-Paper-Tutoræµæ°´çº¿æ‰§è¡Œå®Œæˆ!")
            return results
            
        except Exception as e:
            self.logger.error(f"âŒ æµæ°´çº¿æ‰§è¡Œå¤±è´¥: {e}")
            raise
    
    async def run_single_step(self, step_name: str, input_dir: str, output_dir: str, 
                             user_preferences: Dict[str, Any] = None) -> Dict[str, Any]:
        """è¿è¡Œå•ä¸ªæ­¥éª¤"""
        try:
            self.logger.info(f"ğŸ”„ æ‰§è¡Œå•æ­¥éª¤: {step_name}")
            
            os.makedirs(output_dir, exist_ok=True)
            
            if step_name == "analysis":
                results = await self.paper_analysisor.analyze_papers(input_dir)
                self.paper_analysisor.save_analysis_results(results, output_dir)
                return results
                
            elif step_name == "extraction":
                # éœ€è¦å…ˆè¿è¡Œåˆ†ææ­¥éª¤
                analysis_results = await self.paper_analysisor.analyze_papers(input_dir)
                papers = analysis_results.get('papers', [])
                results = await self.knowledge_extractor.extract_concepts_from_papers(papers)
                self.knowledge_extractor.save_extraction_results(results, output_dir)
                return results
                
            else:
                raise ValueError(f"æœªçŸ¥çš„æ­¥éª¤: {step_name}")
                
        except Exception as e:
            self.logger.error(f"âŒ å•æ­¥éª¤æ‰§è¡Œå¤±è´¥ {step_name}: {e}")
            raise
    
    def _generate_pipeline_report(self, results: Dict[str, Any], 
                                user_preferences: Dict[str, Any] = None) -> str:
        """ç”Ÿæˆæµæ°´çº¿æ•´ä½“æŠ¥å‘Š"""
        lines = ["# ğŸ“ AI-Paper-Tutor å­¦ä¹ æŠ¥å‘Š", ""]
        
        user_prefs = user_preferences or {}
        
        # ç”¨æˆ·é…ç½®
        lines.append("## ğŸ‘¤ å­¦ä¹ é…ç½®")
        lines.append(f"- å­¦ä¹ æ°´å¹³: {user_prefs.get('user_level', 'ä¸­çº§')}")
        lines.append(f"- æ¯æ—¥æ—¶é—´: {user_prefs.get('daily_hours', 2)} å°æ—¶")
        lines.append(f"- å­¦ä¹ å¤©æ•°: {user_prefs.get('total_days', 7)} å¤©")
        lines.append(f"- å­¦ä¹ ç›®æ ‡: {user_prefs.get('learning_goals', 'æ·±å…¥ç†è§£è®ºæ–‡æ ¸å¿ƒæ¦‚å¿µ')}")
        lines.append("")
        
        # è®ºæ–‡åˆ†ææ‘˜è¦
        analysis = results.get('analysis', {})
        if analysis.get('analysis_results'):
            lines.append("## ğŸ“š è®ºæ–‡æ¦‚è§ˆ")
            analysis_results = analysis['analysis_results']
            lines.append(f"- è®ºæ–‡æ€»æ•°: {len(analysis_results)}")
            
            # éš¾åº¦åˆ†å¸ƒ
            difficulties = [r['output']['difficulty_level'] for r in analysis_results.values()]
            difficulty_count = {d: difficulties.count(d) for d in set(difficulties)}
            lines.append("- éš¾åº¦åˆ†å¸ƒ:")
            for level, count in difficulty_count.items():
                lines.append(f"  - {level}: {count} ç¯‡")
            
            # æ€»å­¦ä¹ æ—¶é—´
            total_time = sum(r['output']['reading_time_estimate'] for r in analysis_results.values())
            lines.append(f"- æ€»é¢„ä¼°å­¦ä¹ æ—¶é—´: {total_time} åˆ†é’Ÿ ({total_time/60:.1f} å°æ—¶)")
            lines.append("")
        
        # æ¦‚å¿µæå–æ‘˜è¦
        extraction = results.get('extraction', {})
        if extraction.get('extractions'):
            lines.append("## ğŸ§  æ ¸å¿ƒæ¦‚å¿µ")
            extractions = extraction['extractions']
            
            # ç»Ÿè®¡æ‰€æœ‰æ ¸å¿ƒæ¦‚å¿µ
            all_concepts = []
            for e in extractions.values():
                all_concepts.extend(e['output']['core_concepts'])
            
            # æ¦‚å¿µé¢‘æ¬¡ç»Ÿè®¡
            concept_count = {}
            for concept in all_concepts:
                concept_count[concept] = concept_count.get(concept, 0) + 1
            
            # æ˜¾ç¤ºé«˜é¢‘æ¦‚å¿µ
            top_concepts = sorted(concept_count.items(), key=lambda x: x[1], reverse=True)[:10]
            lines.append("### ğŸ¯ é«˜é¢‘æ ¸å¿ƒæ¦‚å¿µ")
            for concept, count in top_concepts:
                lines.append(f"- **{concept}** (å‡ºç° {count} æ¬¡)")
            lines.append("")
            
            # æ˜¾ç¤ºçŸ¥è¯†é¢†åŸŸ
            all_domains = []
            for e in extractions.values():
                all_domains.extend(e['output']['knowledge_domains'])
            
            domain_count = {}
            for domain in all_domains:
                domain_count[domain] = domain_count.get(domain, 0) + 1
            
            lines.append("### ğŸŒ æ¶‰åŠé¢†åŸŸ")
            for domain, count in sorted(domain_count.items(), key=lambda x: x[1], reverse=True)[:5]:
                lines.append(f"- {domain} ({count} ç¯‡è®ºæ–‡)")
            lines.append("")
        
        # å­¦ä¹ å»ºè®®
        lines.append("## ğŸ’¡ å­¦ä¹ å»ºè®®")
        
        # åŸºäºåˆ†æç»“æœç”Ÿæˆå»ºè®®
        if analysis.get('overall_analysis', {}).get('output', {}).get('learning_suggestions'):
            suggestions = analysis['overall_analysis']['output']['learning_suggestions']
            for suggestion in suggestions[:5]:
                lines.append(f"- {suggestion}")
        else:
            # é»˜è®¤å»ºè®®
            lines.append("- å»ºè®®æŒ‰ç…§æ¨èé¡ºåºé€æ­¥å­¦ä¹ ")
            lines.append("- é‡ç‚¹å…³æ³¨é«˜é¢‘æ ¸å¿ƒæ¦‚å¿µçš„ç†è§£")
            lines.append("- æ¯ç¯‡è®ºæ–‡å­¦ä¹ åè¿›è¡Œæ¦‚å¿µæ€»ç»“")
            lines.append("- å®šæœŸå¤ä¹ å‰ç½®çŸ¥è¯†ç‚¹")
        
        lines.append("")
        
        # æ¨èå­¦ä¹ è·¯å¾„
        if analysis.get('overall_analysis', {}).get('output', {}).get('recommended_order'):
            lines.append("## ğŸ“‹ æ¨èå­¦ä¹ è·¯å¾„")
            recommended_order = analysis['overall_analysis']['output']['recommended_order']
            analysis_results = analysis.get('analysis_results', {})
            
            for i, paper_id in enumerate(recommended_order, 1):
                if paper_id in analysis_results:
                    paper_analysis = analysis_results[paper_id]['output']
                    lines.append(f"### ç¬¬{i}æ­¥: {paper_analysis['title']}")
                    lines.append(f"- **éš¾åº¦**: {paper_analysis['difficulty_level']}")
                    lines.append(f"- **å­¦ä¹ æ—¶é—´**: {paper_analysis['reading_time_estimate']} åˆ†é’Ÿ")
                    lines.append(f"- **æ ¸å¿ƒæ¦‚å¿µ**: {', '.join(paper_analysis['core_concepts'][:3])}")
                    lines.append(f"- **å­¦ä¹ é‡ç‚¹**: {paper_analysis['main_method']}")
                    lines.append("")
        
        # æ–‡ä»¶ä½ç½®è¯´æ˜
        lines.append("## ğŸ“ è¾“å‡ºæ–‡ä»¶è¯´æ˜")
        lines.append("- `analysis/` - è®ºæ–‡åˆ†æè¯¦ç»†ç»“æœ")
        lines.append("- `extraction/` - æ¦‚å¿µæå–å’ŒçŸ¥è¯†å›¾è°±")
        lines.append("- `pipeline_report.md` - æœ¬å­¦ä¹ æŠ¥å‘Š")
        lines.append("")
        
        lines.append("---")
        lines.append("*ç”± AI-Paper-Tutor è‡ªåŠ¨ç”Ÿæˆ*")
        
        return "\n".join(lines)

# ä¾¿æ·å‡½æ•°
async def run_paper_tutor_pipeline(input_dir: str, output_dir: str, 
                                  user_preferences: Dict[str, Any] = None) -> Dict[str, Any]:
    """ä¾¿æ·å‡½æ•°ï¼šè¿è¡Œå®Œæ•´çš„è®ºæ–‡å­¦ä¹ è¾…å¯¼æµæ°´çº¿"""
    orchestrator = PipelineOrchestrator()
    return await orchestrator.run_full_pipeline(input_dir, output_dir, user_preferences)

if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    async def test():
        orchestrator = PipelineOrchestrator()
        print("âœ… PipelineOrchestrator åˆå§‹åŒ–å®Œæˆ")
    
    asyncio.run(test())
