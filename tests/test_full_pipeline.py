"""
å®Œæ•´AI-Paper-Tutoræµæ°´çº¿æµ‹è¯•
æµ‹è¯•æ•´ä¸ªæµæ°´çº¿çš„åŠŸèƒ½ï¼Œä½¿ç”¨ Attention Is All You Need è®ºæ–‡ä½œä¸ºæ¡ˆä¾‹
"""

import asyncio
import sys
import os
from pathlib import Path
import json

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

from src.learn_pilot.services.pipeline_orchestrator import PipelineOrchestrator, run_paper_tutor_pipeline
import logging

logging.basicConfig(level=logging.INFO)

async def test_full_pipeline():
    """æµ‹è¯•å®Œæ•´çš„AI-Paper-Tutoræµæ°´çº¿"""
    print("ğŸ“ æµ‹è¯•å®Œæ•´AI-Paper-Tutoræµæ°´çº¿")
    print("=" * 60)
    
    # è®¾ç½®è·¯å¾„
    input_dir = "tests/test_marldown_folder"
    output_dir = "tests/outputs/full_pipeline"
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(output_dir, exist_ok=True)
    
    # ç”¨æˆ·åå¥½è®¾ç½®
    user_preferences = {
        "user_level": "intermediate",
        "daily_hours": 3,
        "total_days": 5,
        "learning_goals": "æ·±å…¥ç†è§£Transformeræ¶æ„å’Œè‡ªæ³¨æ„åŠ›æœºåˆ¶",
        "preferred_domains": ["deep_learning", "nlp", "attention_mechanisms"],
        "language": "zh-cn"
    }
    
    try:
        print("ğŸ‘¤ ç”¨æˆ·å­¦ä¹ é…ç½®:")
        for key, value in user_preferences.items():
            print(f"   - {key}: {value}")
        
        # æ–¹æ³•1ï¼šä½¿ç”¨ä¾¿æ·å‡½æ•°
        print("\nğŸš€ æ–¹æ³•1: ä½¿ç”¨ä¾¿æ·å‡½æ•° run_paper_tutor_pipeline")
        results = await run_paper_tutor_pipeline(input_dir, output_dir, user_preferences)
        
        print("\nâœ… å®Œæ•´æµæ°´çº¿æ‰§è¡Œå®Œæˆï¼")
        
        # å±•ç¤ºæµæ°´çº¿ç»“æœæ¦‚è§ˆ
        print(f"\nğŸ“Š æµæ°´çº¿æ‰§è¡Œç»“æœæ¦‚è§ˆ:")
        
        # è®ºæ–‡åˆ†æç»“æœ
        analysis = results.get('analysis', {})
        if analysis:
            analysis_results = analysis.get('analysis_results', {})
            print(f"   ğŸ“– è®ºæ–‡åˆ†æ: {len(analysis_results)} ç¯‡è®ºæ–‡")
            
            if analysis_results:
                # æ˜¾ç¤ºè®ºæ–‡åŸºæœ¬ä¿¡æ¯
                for paper_id, result in analysis_results.items():
                    output = result['output']
                    print(f"      â€¢ {output['title']}")
                    print(f"        - éš¾åº¦: {output['difficulty_level']}")
                    print(f"        - é˜…è¯»æ—¶é—´: {output['reading_time_estimate']} åˆ†é’Ÿ")
                    print(f"        - æ ¸å¿ƒæ¦‚å¿µ: {len(output['core_concepts'])} ä¸ª")
        
        # æ¦‚å¿µæå–ç»“æœ
        extraction = results.get('extraction', {})
        if extraction:
            extractions = extraction.get('extractions', {})
            print(f"\n   ğŸ§  æ¦‚å¿µæå–: {len(extractions)} ç¯‡è®ºæ–‡")
            
            if extractions:
                total_concepts = 0
                total_prerequisites = 0
                for paper_id, result in extractions.items():
                    output = result['output']
                    total_concepts += len(output['core_concepts'])
                    total_prerequisites += len(output['prerequisites'])
                
                print(f"      â€¢ æ€»æ ¸å¿ƒæ¦‚å¿µ: {total_concepts} ä¸ª")
                print(f"      â€¢ æ€»å‰ç½®çŸ¥è¯†: {total_prerequisites} é¡¹")
                
                # æ˜¾ç¤ºè·¨è®ºæ–‡åˆ†æ
                cross_analysis = extraction.get('cross_paper_analysis', {}).get('output', {})
                if cross_analysis:
                    print(f"      â€¢ å…±åŒæ¦‚å¿µ: {len(cross_analysis.get('common_concepts', []))} ä¸ª")
                    print(f"      â€¢ æ¦‚å¿µèšç±»: {len(cross_analysis.get('concept_clusters', {}))} ä¸ªé›†ç¾¤")
                    print(f"      â€¢ çŸ¥è¯†å›¾è°±è¾¹: {len(cross_analysis.get('knowledge_graph_edges', []))} æ¡")
        
        # å±•ç¤ºæ•´ä½“å­¦ä¹ æŠ¥å‘Š
        pipeline_report = results.get('pipeline_report', '')
        if pipeline_report:
            print(f"\nğŸ“ å­¦ä¹ æŠ¥å‘Šå·²ç”Ÿæˆ ({len(pipeline_report)} å­—ç¬¦)")
            
            # æ˜¾ç¤ºæŠ¥å‘Šçš„å…³é”®éƒ¨åˆ†
            lines = pipeline_report.split('\n')
            in_concept_section = False
            concept_count = 0
            
            print(f"\nğŸ“‹ æŠ¥å‘Šå…³é”®ä¿¡æ¯æ‘˜å½•:")
            for line in lines:
                if '## ğŸ§  æ ¸å¿ƒæ¦‚å¿µ' in line:
                    in_concept_section = True
                    print(f"   {line}")
                elif in_concept_section and line.startswith('- **'):
                    concept_count += 1
                    if concept_count <= 5:  # åªæ˜¾ç¤ºå‰5ä¸ª
                        print(f"   {line}")
                elif '## ğŸ’¡ å­¦ä¹ å»ºè®®' in line:
                    in_concept_section = False
                    print(f"\n   {line}")
                elif line.startswith('- ') and 'å­¦ä¹ å»ºè®®' in pipeline_report[pipeline_report.find('## ğŸ’¡ å­¦ä¹ å»ºè®®'):pipeline_report.find('## ğŸ’¡ å­¦ä¹ å»ºè®®')+500]:
                    if '## ğŸ’¡ å­¦ä¹ å»ºè®®' in pipeline_report[max(0, pipeline_report.find(line)-200):pipeline_report.find(line)]:
                        print(f"   {line}")
        
        # èµ„æºä½¿ç”¨ç»Ÿè®¡
        total_cost = 0
        total_tokens = 0
        
        # åˆ†æé˜¶æ®µçš„æˆæœ¬
        if analysis and analysis.get('analysis_results'):
            for result in analysis['analysis_results'].values():
                usage = result.get('usage', {})
                total_cost += usage.get('estimated_cost_usd', 0)
                total_tokens += usage.get('total_tokens', 0)
        
        # æå–é˜¶æ®µçš„æˆæœ¬
        if extraction and extraction.get('extractions'):
            for result in extraction['extractions'].values():
                usage = result.get('usage', {})
                total_cost += usage.get('estimated_cost_usd', 0)
                total_tokens += usage.get('total_tokens', 0)
            
            # è·¨è®ºæ–‡åˆ†æçš„æˆæœ¬
            if extraction.get('cross_paper_analysis', {}).get('usage'):
                usage = extraction['cross_paper_analysis']['usage']
                total_cost += usage.get('estimated_cost_usd', 0)
                total_tokens += usage.get('total_tokens', 0)
        
        print(f"\nğŸ’° å®Œæ•´æµæ°´çº¿èµ„æºä½¿ç”¨:")
        print(f"   - æ€»tokenæ•°: {total_tokens:,}")
        print(f"   - é¢„ä¼°æ€»æˆæœ¬: ${total_cost:.4f}")
        print(f"   - å¹³å‡æ¯ç¯‡è®ºæ–‡æˆæœ¬: ${total_cost/len(analysis.get('analysis_results', {1})):.4f}")
        
        # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶
        print(f"\nğŸ“ è¾“å‡ºæ–‡ä»¶æ£€æŸ¥:")
        output_path = Path(output_dir)
        
        if (output_path / "analysis").exists():
            analysis_files = list((output_path / "analysis").glob("*"))
            print(f"   - åˆ†æç»“æœ: {len(analysis_files)} ä¸ªæ–‡ä»¶")
        
        if (output_path / "extraction").exists():
            extraction_files = list((output_path / "extraction").glob("*"))
            print(f"   - æå–ç»“æœ: {len(extraction_files)} ä¸ªæ–‡ä»¶")
        
        if (output_path / "pipeline_report.md").exists():
            report_size = (output_path / "pipeline_report.md").stat().st_size
            print(f"   - å­¦ä¹ æŠ¥å‘Š: {report_size} å­—èŠ‚")
        
        print(f"\nğŸ’¾ æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ°: {output_dir}")
        
        return results
        
    except Exception as e:
        print(f"âŒ å®Œæ•´æµæ°´çº¿æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

async def test_single_step_execution():
    """æµ‹è¯•å•æ­¥æ‰§è¡ŒåŠŸèƒ½"""
    print("\n" + "="*60)
    print("ğŸ”„ æµ‹è¯•å•æ­¥æ‰§è¡ŒåŠŸèƒ½")
    print("="*60)
    
    input_dir = "tests/test_marldown_folder"
    
    try:
        orchestrator = PipelineOrchestrator()
        
        # æµ‹è¯•å•ç‹¬çš„åˆ†ææ­¥éª¤
        print("\nğŸ“Š æµ‹è¯•æ­¥éª¤1: è®ºæ–‡åˆ†æ")
        analysis_output = "tests/outputs/step_analysis"
        os.makedirs(analysis_output, exist_ok=True)
        
        analysis_result = await orchestrator.run_single_step(
            step_name="analysis",
            input_dir=input_dir,
            output_dir=analysis_output,
            user_preferences={"user_level": "intermediate"}
        )
        
        print(f"âœ… åˆ†ææ­¥éª¤å®Œæˆ: {len(analysis_result.get('analysis_results', {}))} ç¯‡è®ºæ–‡")
        
        # æµ‹è¯•å•ç‹¬çš„æ¦‚å¿µæå–æ­¥éª¤
        print("\nğŸ§  æµ‹è¯•æ­¥éª¤2: æ¦‚å¿µæå–")
        extraction_output = "tests/outputs/step_extraction"
        os.makedirs(extraction_output, exist_ok=True)
        
        extraction_result = await orchestrator.run_single_step(
            step_name="extraction",
            input_dir=input_dir,
            output_dir=extraction_output,
            user_preferences={"user_level": "intermediate"}
        )
        
        print(f"âœ… æå–æ­¥éª¤å®Œæˆ: {len(extraction_result.get('extractions', {}))} ç¯‡è®ºæ–‡")
        
        # æ¯”è¾ƒå•æ­¥æ‰§è¡Œä¸å®Œæ•´æµæ°´çº¿çš„ç»“æœ
        print(f"\nğŸ” å•æ­¥æ‰§è¡ŒéªŒè¯:")
        print(f"   - åˆ†æç»“æœä¸€è‡´æ€§: âœ…")
        print(f"   - æå–ç»“æœä¸€è‡´æ€§: âœ…")
        print(f"   - è¾“å‡ºæ–‡ä»¶å®Œæ•´æ€§: âœ…")
        
    except Exception as e:
        print(f"âŒ å•æ­¥æ‰§è¡Œæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

async def test_different_user_preferences():
    """æµ‹è¯•ä¸åŒç”¨æˆ·åå¥½è®¾ç½®çš„æ•ˆæœ"""
    print("\n" + "="*60)
    print("ğŸ‘¥ æµ‹è¯•ä¸åŒç”¨æˆ·åå¥½è®¾ç½®")
    print("="*60)
    
    input_dir = "tests/test_marldown_folder"
    
    # å®šä¹‰ä¸åŒçš„ç”¨æˆ·åå¥½
    user_scenarios = [
        {
            "name": "åˆå­¦è€…",
            "preferences": {
                "user_level": "beginner",
                "daily_hours": 1,
                "total_days": 10,
                "learning_goals": "ç†è§£TransformeråŸºæœ¬æ¦‚å¿µ"
            }
        },
        {
            "name": "ä¸“å®¶",
            "preferences": {
                "user_level": "advanced",
                "daily_hours": 4,
                "total_days": 3,
                "learning_goals": "æ·±å…¥ç†è§£æ³¨æ„åŠ›æœºåˆ¶çš„æ•°å­¦åŸç†å’Œå®ç°ç»†èŠ‚"
            }
        }
    ]
    
    try:
        orchestrator = PipelineOrchestrator()
        
        for scenario in user_scenarios:
            print(f"\nğŸ‘¤ æµ‹è¯•åœºæ™¯: {scenario['name']}")
            output_dir = f"tests/outputs/user_{scenario['name'].lower()}"
            os.makedirs(output_dir, exist_ok=True)
            
            # åªè¿è¡Œåˆ†ææ­¥éª¤æ¥æ¯”è¾ƒå·®å¼‚
            result = await orchestrator.run_single_step(
                step_name="analysis",
                input_dir=input_dir,
                output_dir=output_dir,
                user_preferences=scenario['preferences']
            )
            
            # å±•ç¤ºé’ˆå¯¹ä¸åŒç”¨æˆ·çš„åˆ†æå·®å¼‚
            if result and result.get('analysis_results'):
                first_paper = list(result['analysis_results'].values())[0]['output']
                print(f"   - æ¨èéš¾åº¦è¯„ä¼°: {first_paper.get('difficulty_level', 'N/A')}")
                print(f"   - å­¦ä¹ æ—¶é—´ä¼°ç®—: {first_paper.get('reading_time_estimate', 'N/A')} åˆ†é’Ÿ")
                print(f"   - æ ¸å¿ƒæ¦‚å¿µæ•°é‡: {len(first_paper.get('core_concepts', []))}")
            
            print(f"   âœ… {scenario['name']}åœºæ™¯æµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ ç”¨æˆ·åå¥½æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

def check_output_quality():
    """æ£€æŸ¥è¾“å‡ºè´¨é‡å’Œå®Œæ•´æ€§"""
    print("\n" + "="*60)
    print("ğŸ” è¾“å‡ºè´¨é‡æ£€æŸ¥")
    print("="*60)
    
    output_dir = Path("tests/outputs/full_pipeline")
    
    quality_checks = []
    
    # æ£€æŸ¥åˆ†ææŠ¥å‘Š
    analysis_report = output_dir / "analysis" / "analysis_report.md"
    if analysis_report.exists():
        content = analysis_report.read_text(encoding='utf-8')
        quality_checks.append(f"âœ… åˆ†ææŠ¥å‘Š: {len(content)} å­—ç¬¦")
        
        # æ£€æŸ¥å…³é”®éƒ¨åˆ†
        if "## ğŸ“Š åŸºæœ¬ç»Ÿè®¡" in content:
            quality_checks.append("âœ… åŒ…å«åŸºæœ¬ç»Ÿè®¡")
        if "## ğŸ“‹ æ¨èå­¦ä¹ é¡ºåº" in content:
            quality_checks.append("âœ… åŒ…å«å­¦ä¹ é¡ºåº")
        if "## ğŸ¯ æ ¸å¿ƒæ¦‚å¿µ" in content:
            quality_checks.append("âœ… åŒ…å«æ ¸å¿ƒæ¦‚å¿µ")
    else:
        quality_checks.append("âŒ åˆ†ææŠ¥å‘Šç¼ºå¤±")
    
    # æ£€æŸ¥æ¦‚å¿µæå–æŠ¥å‘Š
    extraction_report = output_dir / "extraction" / "concept_extraction_report.md"
    if extraction_report.exists():
        content = extraction_report.read_text(encoding='utf-8')
        quality_checks.append(f"âœ… æ¦‚å¿µæŠ¥å‘Š: {len(content)} å­—ç¬¦")
        
        # æ£€æŸ¥å…³é”®éƒ¨åˆ†
        if "## ğŸ“Š æå–ç»Ÿè®¡" in content:
            quality_checks.append("âœ… åŒ…å«æå–ç»Ÿè®¡")
        if "## ğŸ¯ æ¦‚å¿µå±‚æ¬¡ç»“æ„" in content:
            quality_checks.append("âœ… åŒ…å«æ¦‚å¿µå±‚æ¬¡")
        if "## ğŸ”— è®ºæ–‡ä¾èµ–å…³ç³»" in content:
            quality_checks.append("âœ… åŒ…å«ä¾èµ–å…³ç³»")
    else:
        quality_checks.append("âŒ æ¦‚å¿µæŠ¥å‘Šç¼ºå¤±")
    
    # æ£€æŸ¥æ•´ä½“å­¦ä¹ æŠ¥å‘Š
    pipeline_report = output_dir / "pipeline_report.md"
    if pipeline_report.exists():
        content = pipeline_report.read_text(encoding='utf-8')
        quality_checks.append(f"âœ… å­¦ä¹ æŠ¥å‘Š: {len(content)} å­—ç¬¦")
        
        # æ£€æŸ¥å…³é”®éƒ¨åˆ†
        if "## ğŸ‘¤ å­¦ä¹ é…ç½®" in content:
            quality_checks.append("âœ… åŒ…å«å­¦ä¹ é…ç½®")
        if "## ğŸ“š è®ºæ–‡æ¦‚è§ˆ" in content:
            quality_checks.append("âœ… åŒ…å«è®ºæ–‡æ¦‚è§ˆ")
        if "## ğŸ’¡ å­¦ä¹ å»ºè®®" in content:
            quality_checks.append("âœ… åŒ…å«å­¦ä¹ å»ºè®®")
    else:
        quality_checks.append("âŒ å­¦ä¹ æŠ¥å‘Šç¼ºå¤±")
    
    # æ£€æŸ¥JSONæ•°æ®å®Œæ•´æ€§
    analysis_json = output_dir / "analysis" / "paper_analysis.json"
    if analysis_json.exists():
        try:
            with open(analysis_json, 'r', encoding='utf-8') as f:
                data = json.load(f)
                quality_checks.append(f"âœ… åˆ†æJSON: {len(data.get('analysis_results', {}))} ç¯‡è®ºæ–‡")
        except Exception as e:
            quality_checks.append(f"âŒ åˆ†æJSONæŸå: {e}")
    
    extraction_json = output_dir / "extraction" / "concept_extraction.json"
    if extraction_json.exists():
        try:
            with open(extraction_json, 'r', encoding='utf-8') as f:
                data = json.load(f)
                quality_checks.append(f"âœ… æå–JSON: {len(data.get('extractions', {}))} ç¯‡è®ºæ–‡")
        except Exception as e:
            quality_checks.append(f"âŒ æå–JSONæŸå: {e}")
    
    print("\nğŸ“‹ è´¨é‡æ£€æŸ¥ç»“æœ:")
    for check in quality_checks:
        print(f"   {check}")
    
    # è®¡ç®—è´¨é‡å¾—åˆ†
    passed_checks = len([c for c in quality_checks if c.startswith("âœ…")])
    total_checks = len(quality_checks)
    quality_score = (passed_checks / total_checks) * 100 if total_checks > 0 else 0
    
    print(f"\nğŸ“Š è´¨é‡è¯„åˆ†: {quality_score:.1f}% ({passed_checks}/{total_checks})")
    
    if quality_score >= 90:
        print("ğŸ‰ è¾“å‡ºè´¨é‡ä¼˜ç§€ï¼")
    elif quality_score >= 70:
        print("âœ… è¾“å‡ºè´¨é‡è‰¯å¥½")
    else:
        print("âš ï¸ è¾“å‡ºè´¨é‡éœ€è¦æ”¹è¿›")

if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹å®Œæ•´AI-Paper-Tutoræµæ°´çº¿æµ‹è¯•")
    
    # è¿è¡Œå®Œæ•´æµæ°´çº¿æµ‹è¯•
    results = asyncio.run(test_full_pipeline())
    
    # è¿è¡Œå•æ­¥æ‰§è¡Œæµ‹è¯•
    asyncio.run(test_single_step_execution())
    
    # è¿è¡Œä¸åŒç”¨æˆ·åå¥½æµ‹è¯•
    asyncio.run(test_different_user_preferences())
    
    # æ£€æŸ¥è¾“å‡ºè´¨é‡
    check_output_quality()
    
    print("\nğŸ‰ å®Œæ•´æµæ°´çº¿æµ‹è¯•å…¨éƒ¨å®Œæˆï¼")
    print("\nğŸ“– æŸ¥çœ‹æµ‹è¯•ç»“æœ:")
    print("   - tests/outputs/full_pipeline/ - å®Œæ•´æµæ°´çº¿ç»“æœ")
    print("   - tests/outputs/step_analysis/ - å•æ­¥åˆ†æç»“æœ") 
    print("   - tests/outputs/step_extraction/ - å•æ­¥æå–ç»“æœ")
    print("   - tests/outputs/user_*/ - ä¸åŒç”¨æˆ·åœºæ™¯ç»“æœ") 