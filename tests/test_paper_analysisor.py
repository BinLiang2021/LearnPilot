"""
PaperAnalysisor å®é™…è¿è¡Œæµ‹è¯•
æµ‹è¯•è®ºæ–‡åˆ†æå™¨çš„åŠŸèƒ½ï¼Œä½¿ç”¨ Attention Is All You Need è®ºæ–‡ä½œä¸ºæ¡ˆä¾‹
"""

import asyncio
import sys
import os
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

from src.learn_pilot.agents.paper_analysisor import PaperAnalysisor, analyze_papers_directory
import logging

logging.basicConfig(level=logging.INFO)

async def test_paper_analysisor():
    """æµ‹è¯•è®ºæ–‡åˆ†æå™¨"""
    print("ğŸ” æµ‹è¯• PaperAnalysisor")
    print("=" * 50)
    
    # è®¾ç½®è·¯å¾„
    input_dir = "tests/test_marldown_folder"
    output_dir = "tests/outputs/paper_analysis"
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(output_dir, exist_ok=True)
    
    try:
        # æ–¹æ³•1ï¼šç›´æ¥ä½¿ç”¨ä¾¿æ·å‡½æ•°
        print("\nğŸ“ æ–¹æ³•1: ä½¿ç”¨ä¾¿æ·å‡½æ•° analyze_papers_directory")
        results = await analyze_papers_directory(input_dir, output_dir)
        
        print("\nâœ… åˆ†æå®Œæˆï¼ç»“æœæ¦‚è§ˆ:")
        print(f"ğŸ“Š åˆ†æçš„è®ºæ–‡æ•°é‡: {len(results.get('papers', []))}")
        print(f"ğŸ“‹ åˆ†æç»“æœ: {len(results.get('analysis_results', {}))}")
        
        # å±•ç¤ºç¬¬ä¸€ç¯‡è®ºæ–‡çš„åˆ†æç»“æœ
        analysis_results = results.get('analysis_results', {})
        if analysis_results:
            first_paper_id = list(analysis_results.keys())[0]
            first_result = analysis_results[first_paper_id]['output']
            
            print(f"\nğŸ“– è®ºæ–‡ã€Š{first_result['title']}ã€‹åˆ†æç»“æœ:")
            print(f"   - ç ”ç©¶é—®é¢˜: {first_result['research_problem'][:100]}...")
            print(f"   - ä¸»è¦æ–¹æ³•: {first_result['main_method'][:100]}...")
            print(f"   - éš¾åº¦ç­‰çº§: {first_result['difficulty_level']}")
            print(f"   - é˜…è¯»æ—¶é—´ä¼°ç®—: {first_result['reading_time_estimate']} åˆ†é’Ÿ")
            print(f"   - æŠ€æœ¯å¤æ‚åº¦: {first_result['technical_complexity']}")
            print(f"   - æ ¸å¿ƒæ¦‚å¿µæ•°é‡: {len(first_result['core_concepts'])}")
            print(f"   - å‰ç½®çŸ¥è¯†æ•°é‡: {len(first_result['prerequisites'])}")
            
            print(f"\nğŸ¯ å‰5ä¸ªæ ¸å¿ƒæ¦‚å¿µ:")
            for i, concept in enumerate(first_result['core_concepts'][:5], 1):
                print(f"   {i}. {concept}")
            
            print(f"\nğŸ“š å‰3ä¸ªå‰ç½®çŸ¥è¯†:")
            for i, prereq in enumerate(first_result['prerequisites'][:3], 1):
                print(f"   {i}. {prereq}")
        
        # å±•ç¤ºæ•´ä½“åˆ†æ
        overall = results.get('overall_analysis', {}).get('output', {})
        if overall:
            print(f"\nğŸ“ˆ æ•´ä½“åˆ†æ:")
            if overall.get('difficulty_distribution'):
                print(f"   - éš¾åº¦åˆ†å¸ƒ: {overall['difficulty_distribution']}")
            if overall.get('total_estimated_time'):
                print(f"   - æ€»å­¦ä¹ æ—¶é—´: {overall['total_estimated_time']} åˆ†é’Ÿ")
            if overall.get('recommended_order'):
                print(f"   - æ¨èå­¦ä¹ é¡ºåº: {overall['recommended_order']}")
        
        print(f"\nğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {output_dir}")
        
        # æ–¹æ³•2ï¼šç›´æ¥ä½¿ç”¨ç±»å®ä¾‹
        print("\nğŸ“ æ–¹æ³•2: ç›´æ¥ä½¿ç”¨ PaperAnalysisor ç±»")
        analyzer = PaperAnalysisor()
        results2 = await analyzer.analyze_papers(input_dir)
        
        print(f"âœ… ç¬¬äºŒæ¬¡åˆ†æå®Œæˆï¼Œè®ºæ–‡æ•°é‡: {len(results2.get('papers', []))}")
        
        # æµ‹è¯• token ä½¿ç”¨æƒ…å†µ
        total_cost = 0
        total_tokens = 0
        for paper_id, result in results.get('analysis_results', {}).items():
            usage = result.get('usage', {})
            total_cost += usage.get('estimated_cost_usd', 0)
            total_tokens += usage.get('total_tokens', 0)
        
        print(f"\nğŸ’° èµ„æºä½¿ç”¨ç»Ÿè®¡:")
        print(f"   - æ€»tokenæ•°: {total_tokens:,}")
        print(f"   - é¢„ä¼°æˆæœ¬: ${total_cost:.4f}")
        
        return results
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

async def test_single_paper_analysis():
    """æµ‹è¯•å•ç¯‡è®ºæ–‡åˆ†æçš„è¯¦ç»†è¾“å‡º"""
    print("\n" + "="*50)
    print("ğŸ”¬ è¯¦ç»†å•ç¯‡è®ºæ–‡åˆ†ææµ‹è¯•")
    print("="*50)
    
    try:
        from src.learn_pilot.literature_utils.markdown_parser import parse_papers_from_directory
        from src.learn_pilot.agents.paper_analysisor import PaperAnalysisor
        
        # è§£æè®ºæ–‡
        papers = parse_papers_from_directory("tests/test_marldown_folder")
        if not papers:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°è®ºæ–‡æ–‡ä»¶")
            return
        
        paper = papers[0]  # å–ç¬¬ä¸€ç¯‡è®ºæ–‡
        print(f"ğŸ“– åˆ†æè®ºæ–‡: {paper.title}")
        print(f"ğŸ“ æ‘˜è¦é•¿åº¦: {len(paper.abstract)} å­—ç¬¦")
        print(f"ğŸ“‘ ç« èŠ‚æ•°é‡: {len(paper.sections)}")
        
        # åˆ›å»ºåˆ†æå™¨å¹¶åˆ†æ
        analyzer = PaperAnalysisor()
        result = await analyzer._analyze_single_paper_with_llm(paper)
        
        analysis = result['output']
        usage = result['usage']
        
        print(f"\nğŸ“Š è¯¦ç»†åˆ†æç»“æœ:")
        print(f"   - æ ‡é¢˜: {analysis['title']}")
        print(f"   - ä½œè€…: {', '.join(analysis['authors'])}")
        print(f"   - ç ”ç©¶é—®é¢˜: {analysis['research_problem']}")
        print(f"   - ä¸»è¦æ–¹æ³•: {analysis['main_method']}")
        
        print(f"\nğŸ¯ æ ¸å¿ƒæ¦‚å¿µ ({len(analysis['core_concepts'])} ä¸ª):")
        for i, concept in enumerate(analysis['core_concepts'], 1):
            print(f"   {i:2d}. {concept}")
        
        print(f"\nğŸ“š å‰ç½®çŸ¥è¯† ({len(analysis['prerequisites'])} ä¸ª):")
        for i, prereq in enumerate(analysis['prerequisites'], 1):
            print(f"   {i:2d}. {prereq}")
        
        print(f"\nğŸ† å…³é”®è´¡çŒ®:")
        for i, contrib in enumerate(analysis['key_contributions'], 1):
            print(f"   {i}. {contrib}")
        
        print(f"\nğŸ“– ç« èŠ‚æ‘˜è¦:")
        for section, summary in analysis['section_summary'].items():
            print(f"   - {section}: {summary[:100]}...")
        
        print(f"\nğŸ’° æœ¬æ¬¡åˆ†æèµ„æºä½¿ç”¨:")
        print(f"   - è¾“å…¥tokens: {usage['input_tokens']:,}")
        print(f"   - è¾“å‡ºtokens: {usage['output_tokens']:,}")
        print(f"   - æ€»tokens: {usage['total_tokens']:,}")
        print(f"   - é¢„ä¼°æˆæœ¬: ${usage['estimated_cost_usd']:.4f}")
        
    except Exception as e:
        print(f"âŒ è¯¦ç»†åˆ†ææµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹ PaperAnalysisor åŠŸèƒ½æµ‹è¯•")
    
    # è¿è¡ŒåŸºæœ¬æµ‹è¯•
    results = asyncio.run(test_paper_analysisor())
    
    # è¿è¡Œè¯¦ç»†æµ‹è¯•
    asyncio.run(test_single_paper_analysis())
    
    print("\nğŸ‰ PaperAnalysisor æµ‹è¯•å®Œæˆï¼")
