# 🧠 概念提取与知识图谱报告

## 📊 提取统计
- 处理论文数: 1
- 核心概念总数: 7
- 共同概念数: 6

## 🎯 概念层次结构
### 1
- 深度学习(Deep Learning)
- 神经网络(Neural Networks)
- 自然语言处理(NLP)
- 机器学习(Machine Learning)

### 2
- Transformer模型
- 多头自注意力(multi-head self-attention)
- 序列到序列模型(sequence-to-sequence models)

### 3
- 自注意力机制(self-attention mechanism)
- 缩放点积注意力(scaled dot-product attention)
- 自回归模型(auto-regressive models)

## 📚 推荐学习顺序

## 🎭 概念聚类
### 维度-作用的知识集群
- 自注意力机制
- 点积技术

## 🔗 论文依赖关系
- **paper_1** → **paper_2**
  - 原因: 从自然语言处理的理论如Transformer的基础逐步进入领域应用

## 📋 各论文概念详情
### paper_1
- **难度**: advanced
- **学习时间**: 240 分钟
- **领域**: 自然语言处理, 深度学习, 机器学习
- **核心概念**: Transformer模型, 多头自注意力(multi-head self-attention), 自注意力机制(self-attention mechanism), 编码器-解码器注意力层(encoder-decoder attention layers), 序列到序列模型(sequence-to-sequence models)
- **前置知识**: 4 项
